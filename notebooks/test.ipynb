{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learnNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading scikit_learn-1.6.0-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\harshika.pathak\\appdata\\local\\miniconda3\\envs\\gpt\\lib\\site-packages (from scikit-learn) (2.2.1)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.0-cp312-cp312-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 2.9/11.1 MB 15.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.3/11.1 MB 18.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 19.3 MB/s eta 0:00:00\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.14.1-cp312-cp312-win_amd64.whl (44.5 MB)\n",
      "   ---------------------------------------- 0.0/44.5 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 5.8/44.5 MB 27.0 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 11.3/44.5 MB 27.1 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 17.3/44.5 MB 27.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 21.8/44.5 MB 25.5 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 24.4/44.5 MB 22.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 26.7/44.5 MB 21.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 29.6/44.5 MB 20.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 32.8/44.5 MB 19.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 36.2/44.5 MB 18.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 38.3/44.5 MB 18.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 39.8/44.5 MB 17.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 41.7/44.5 MB 16.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.5/44.5 MB 16.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.5/44.5 MB 15.1 MB/s eta 0:00:00\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.0 scipy-1.14.1 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 400 images\n",
      "Test set size: 100 images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Paths to your images and annotations\n",
    "image_dir = r'C:\\Users\\harshika.pathak\\Desktop\\WORK\\object_detection\\combined_dataset'\n",
    "annotation_dir = r'C:\\Users\\harshika.pathak\\Desktop\\WORK\\object_detection\\xml_files'\n",
    "\n",
    "# List all image files\n",
    "image_files = [f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "\n",
    "# You can adjust the test size based on your needs\n",
    "test_size = 0.2  # 80% train, 20% test\n",
    "\n",
    "# Split image files into train and test sets\n",
    "train_files, test_files = train_test_split(image_files, test_size=test_size, random_state=42)\n",
    "\n",
    "# Create directories for the split datasets (train/test)\n",
    "train_image_dir = 'train_images'\n",
    "test_image_dir = 'test_images'\n",
    "train_annotation_dir = 'train_annotations'\n",
    "test_annotation_dir = 'test_annotations'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(train_image_dir, exist_ok=True)\n",
    "os.makedirs(test_image_dir, exist_ok=True)\n",
    "os.makedirs(train_annotation_dir, exist_ok=True)\n",
    "os.makedirs(test_annotation_dir, exist_ok=True)\n",
    "\n",
    "# Move images and annotations to the new directories\n",
    "for image_file in train_files:\n",
    "    # Copy image to train\n",
    "    shutil.copy(os.path.join(image_dir, image_file), os.path.join(train_image_dir, image_file))\n",
    "    \n",
    "    # Copy corresponding annotation file (e.g., if annotations are in XML format)\n",
    "    annotation_file = image_file.replace('.png', '.xml')  # Assuming XML annotations\n",
    "    shutil.copy(os.path.join(annotation_dir, annotation_file), os.path.join(train_annotation_dir, annotation_file))\n",
    "\n",
    "for image_file in test_files:\n",
    "    # Copy image to test\n",
    "    shutil.copy(os.path.join(image_dir, image_file), os.path.join(test_image_dir, image_file))\n",
    "    \n",
    "    # Copy corresponding annotation file\n",
    "    annotation_file = image_file.replace('.png', '.xml')\n",
    "    shutil.copy(os.path.join(annotation_dir, annotation_file), os.path.join(test_annotation_dir, annotation_file))\n",
    "\n",
    "print(f\"Train set size: {len(train_files)} images\")\n",
    "print(f\"Test set size: {len(test_files)} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
