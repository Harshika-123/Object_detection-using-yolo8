{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpyNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached numpy-2.2.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Using cached numpy-2.2.1-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-2.2.1\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 200 combined images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:07<00:00, 25.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created in directory: combined_dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Parameters\n",
    "input_folder = r\"C:\\Users\\harshika.pathak\\Desktop\\WORK\\object_detection\\stars\"  # Folder containing 3-4 images\n",
    "output_folder = \"combined_dataset\"  # Folder to save the dataset\n",
    "dataset_size = 200 # Total number of images in the dataset\n",
    "page_size = (512, 512)  # Size of the output page (width, height)\n",
    "image_size = (64, 64)  # Standard size for input images (width, height)\n",
    "max_images_per_page = 4  # Maximum number of images to place on a single page\n",
    "\n",
    "# Function to load and resize all images from the input folder\n",
    "def load_and_resize_images(input_folder, image_size):\n",
    "    images = []\n",
    "    for filename in os.listdir(input_folder):\n",
    "        filepath = os.path.join(input_folder, filename)\n",
    "        img = cv2.imread(filepath, cv2.IMREAD_UNCHANGED)  # Read the image\n",
    "        if img is not None:\n",
    "            # Convert grayscale or RGBA to RGB\n",
    "            if len(img.shape) == 2:  # Grayscale image\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "            elif img.shape[2] == 4:  # RGBA image\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_RGBA2RGB)\n",
    "            # Resize the image to the target size\n",
    "            resized_img = cv2.resize(img, image_size, interpolation=cv2.INTER_AREA)\n",
    "            images.append(resized_img)\n",
    "    if len(images) == 0:\n",
    "        raise ValueError(\"No valid images found in the input folder.\")\n",
    "    return images\n",
    "\n",
    "# Function to place multiple images on a single page without overriding\n",
    "def create_combined_page(page_size, images, max_images):\n",
    "    # Create a blank page\n",
    "    page = np.ones((page_size[1], page_size[0], 3), dtype=np.uint8) *255\n",
    "\n",
    "    # Randomly decide the number of images to place\n",
    "    num_images = np.random.randint(1, max_images + 1)\n",
    "\n",
    "    for _ in range(num_images):\n",
    "        # Randomly select an image\n",
    "        img = images[np.random.randint(len(images))]\n",
    "\n",
    "        # Randomly place the image on the page\n",
    "        x_offset = np.random.randint(0, page_size[0] - img.shape[1])\n",
    "        y_offset = np.random.randint(0, page_size[1] - img.shape[0])\n",
    "\n",
    "        # Overlay the image onto the page without overriding\n",
    "        for y in range(img.shape[0]):\n",
    "            for x in range(img.shape[1]):\n",
    "                if np.any(img[y, x] > 0):  # Check if the pixel is non-black\n",
    "                    page[y_offset + y, x_offset + x] = img[y, x]\n",
    "\n",
    "    return page\n",
    "\n",
    "# Function to create the dataset\n",
    "def create_dataset(input_folder, output_folder, dataset_size, page_size, image_size, max_images_per_page):\n",
    "    # Load and resize input images\n",
    "    images = load_and_resize_images(input_folder, image_size)\n",
    "\n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    print(f\"Generating {dataset_size} combined images...\")\n",
    "    for i in tqdm(range(dataset_size)):\n",
    "        # Create a combined page\n",
    "        page = create_combined_page(page_size, images, max_images_per_page)\n",
    "\n",
    "        # Save the generated page\n",
    "        output_path = os.path.join(output_folder, f\"page_{i+1:04d}.png\")\n",
    "        cv2.imwrite(output_path, page)\n",
    "\n",
    "    print(f\"Dataset created in directory: {output_folder}\")\n",
    "\n",
    "# Generate the dataset\n",
    "create_dataset(input_folder, output_folder, dataset_size, page_size, image_size, max_images_per_page)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "\n",
    "# Function to parse XML annotation file and extract bounding boxes\n",
    "def parse_annotation(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    bboxes = []\n",
    "\n",
    "    for obj in root.findall(\"object\"):\n",
    "        bbox = obj.find(\"bndbox\")\n",
    "        bboxes.append({\n",
    "            \"xmin\": int(bbox.find(\"xmin\").text),\n",
    "            \"ymin\": int(bbox.find(\"ymin\").text),\n",
    "            \"xmax\": int(bbox.find(\"xmax\").text),\n",
    "            \"ymax\": int(bbox.find(\"ymax\").text),\n",
    "        })\n",
    "\n",
    "    return bboxes, root\n",
    "\n",
    "# Function to save updated annotations\n",
    "def save_annotation(xml_file, root, bboxes, output_dir, new_name):\n",
    "    for obj, bbox in zip(root.findall(\"object\"), bboxes):\n",
    "        obj.find(\"bndbox/xmin\").text = str(bbox[\"xmin\"])\n",
    "        obj.find(\"bndbox/ymin\").text = str(bbox[\"ymin\"])\n",
    "        obj.find(\"bndbox/xmax\").text = str(bbox[\"xmax\"])\n",
    "        obj.find(\"bndbox/ymax\").text = str(bbox[\"ymax\"])\n",
    "\n",
    "    tree = ET.ElementTree(root)\n",
    "    tree.write(os.path.join(output_dir, new_name + \".xml\"))\n",
    "\n",
    "# Function to apply data augmentation\n",
    "def augment_image(image, bboxes):\n",
    "    h, w = image.shape[:2]\n",
    "    augmented_images = []\n",
    "\n",
    "    # Flip horizontally\n",
    "    flipped_image = cv2.flip(image, 1)\n",
    "    flipped_bboxes = [{\n",
    "        \"xmin\": w - bbox[\"xmax\"],\n",
    "        \"ymin\": bbox[\"ymin\"],\n",
    "        \"xmax\": w - bbox[\"xmin\"],\n",
    "        \"ymax\": bbox[\"ymax\"],\n",
    "    } for bbox in bboxes]\n",
    "    augmented_images.append((flipped_image, flipped_bboxes))\n",
    "\n",
    "    # Add Gaussian noise\n",
    "    noise = np.random.normal(0, 25, image.shape).astype(np.uint8)\n",
    "    noisy_image = cv2.add(image, noise)\n",
    "    augmented_images.append((noisy_image, bboxes))\n",
    "\n",
    "    # Apply Gaussian blur\n",
    "    blurred_image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "    augmented_images.append((blurred_image, bboxes))\n",
    "\n",
    "    # Skewness transformation (perspective warp)\n",
    "    pts1 = np.float32([[0, 0], [w, 0], [0, h], [w, h]])\n",
    "    pts2 = np.float32([[0, 0], [w, 0], [int(0.1 * w), h], [int(0.9 * w), h]])\n",
    "    matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    skewed_image = cv2.warpPerspective(image, matrix, (w, h))\n",
    "    skewed_bboxes = []\n",
    "    for bbox in bboxes:\n",
    "        points = np.array([\n",
    "            [bbox[\"xmin\"], bbox[\"ymin\"]],\n",
    "            [bbox[\"xmax\"], bbox[\"ymin\"]],\n",
    "            [bbox[\"xmax\"], bbox[\"ymax\"]],\n",
    "            [bbox[\"xmin\"], bbox[\"ymax\"]]\n",
    "        ], dtype=np.float32)\n",
    "        transformed_points = cv2.perspectiveTransform(points[None, :, :], matrix)[0]\n",
    "        x_coords, y_coords = transformed_points[:, 0], transformed_points[:, 1]\n",
    "        skewed_bboxes.append({\n",
    "            \"xmin\": int(min(x_coords)),\n",
    "            \"ymin\": int(min(y_coords)),\n",
    "            \"xmax\": int(max(x_coords)),\n",
    "            \"ymax\": int(max(y_coords))\n",
    "        })\n",
    "    augmented_images.append((skewed_image, skewed_bboxes))\n",
    "\n",
    "    return augmented_images\n",
    "\n",
    "# Main function\n",
    "input_images_dir = r\"C:\\Users\\harshika.pathak\\Desktop\\WORK\\object_detection\\combined_dataset\"\n",
    "input_annotations_dir = r\"C:\\Users\\harshika.pathak\\Desktop\\WORK\\object_detection\\annotated_images\"\n",
    "output_images_dir = \"augmented images\"\n",
    "output_annotations_dir = \"augmented annotations\"\n",
    "\n",
    "os.makedirs(output_images_dir, exist_ok=True)\n",
    "os.makedirs(output_annotations_dir, exist_ok=True)\n",
    "\n",
    "for image_file in os.listdir(input_images_dir):\n",
    "    if not image_file.endswith(\".png\"):\n",
    "        continue\n",
    "\n",
    "    image_path = os.path.join(input_images_dir, image_file)\n",
    "    xml_file = os.path.join(input_annotations_dir, image_file.replace(\".png\", \".xml\"))\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    bboxes, root = parse_annotation(xml_file)\n",
    "\n",
    "    augmentations = augment_image(image, bboxes)\n",
    "\n",
    "    for idx, (aug_image, aug_bboxes) in enumerate(augmentations):\n",
    "        new_name = f\"{os.path.splitext(image_file)[0]}_aug{idx}\"\n",
    "        cv2.imwrite(os.path.join(output_images_dir, new_name + \".png\"), aug_image)\n",
    "        save_annotation(xml_file, root, aug_bboxes, output_annotations_dir, new_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvisionNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading torchvision-0.20.1-cp312-cp312-win_amd64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\harshika.pathak\\appdata\\local\\miniconda3\\envs\\gpt\\lib\\site-packages (from torchvision) (2.2.1)\n",
      "Collecting torch==2.5.1 (from torchvision)\n",
      "  Downloading torch-2.5.1-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\harshika.pathak\\appdata\\local\\miniconda3\\envs\\gpt\\lib\\site-packages (from torchvision) (11.0.0)\n",
      "Collecting filelock (from torch==2.5.1->torchvision)\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\harshika.pathak\\appdata\\local\\miniconda3\\envs\\gpt\\lib\\site-packages (from torch==2.5.1->torchvision) (4.12.2)\n",
      "Collecting networkx (from torch==2.5.1->torchvision)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch==2.5.1->torchvision)\n",
      "  Using cached jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fsspec (from torch==2.5.1->torchvision)\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\harshika.pathak\\appdata\\local\\miniconda3\\envs\\gpt\\lib\\site-packages (from torch==2.5.1->torchvision) (75.1.0)\n",
      "Collecting sympy==1.13.1 (from torch==2.5.1->torchvision)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch==2.5.1->torchvision)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.5.1->torchvision)\n",
      "  Using cached MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Downloading torchvision-0.20.1-cp312-cp312-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 9.2 MB/s eta 0:00:00\n",
      "Downloading torch-2.5.1-cp312-cp312-win_amd64.whl (203.0 MB)\n",
      "   ---------------------------------------- 0.0/203.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 5.5/203.0 MB 25.8 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 12.3/203.0 MB 29.7 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 15.7/203.0 MB 30.9 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 15.7/203.0 MB 30.9 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 15.7/203.0 MB 30.9 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 15.7/203.0 MB 30.9 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 15.7/203.0 MB 30.9 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 16.5/203.0 MB 9.7 MB/s eta 0:00:20\n",
      "   --- ------------------------------------ 18.4/203.0 MB 9.6 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 21.8/203.0 MB 10.2 MB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 26.0/203.0 MB 11.0 MB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 29.9/203.0 MB 11.7 MB/s eta 0:00:15\n",
      "   ------ --------------------------------- 34.3/203.0 MB 12.5 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 38.5/203.0 MB 13.0 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 42.7/203.0 MB 13.5 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 45.1/203.0 MB 13.3 MB/s eta 0:00:12\n",
      "   --------- ------------------------------ 47.4/203.0 MB 13.2 MB/s eta 0:00:12\n",
      "   --------- ------------------------------ 49.8/203.0 MB 13.1 MB/s eta 0:00:12\n",
      "   ---------- ----------------------------- 52.4/203.0 MB 13.1 MB/s eta 0:00:12\n",
      "   ---------- ----------------------------- 55.3/203.0 MB 13.0 MB/s eta 0:00:12\n",
      "   ----------- ---------------------------- 58.2/203.0 MB 13.1 MB/s eta 0:00:12\n",
      "   ----------- ---------------------------- 60.6/203.0 MB 13.0 MB/s eta 0:00:11\n",
      "   ------------ --------------------------- 62.9/203.0 MB 12.9 MB/s eta 0:00:11\n",
      "   ------------ --------------------------- 65.5/203.0 MB 12.9 MB/s eta 0:00:11\n",
      "   ------------- -------------------------- 67.9/203.0 MB 12.9 MB/s eta 0:00:11\n",
      "   ------------- -------------------------- 70.8/203.0 MB 12.9 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 73.9/203.0 MB 13.0 MB/s eta 0:00:10\n",
      "   --------------- ------------------------ 76.3/203.0 MB 12.9 MB/s eta 0:00:10\n",
      "   --------------- ------------------------ 78.6/203.0 MB 12.8 MB/s eta 0:00:10\n",
      "   --------------- ------------------------ 81.0/203.0 MB 12.8 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 83.6/203.0 MB 12.8 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 86.0/203.0 MB 12.8 MB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 88.1/203.0 MB 12.6 MB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 90.2/203.0 MB 12.6 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 92.5/203.0 MB 12.5 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 95.2/203.0 MB 12.5 MB/s eta 0:00:09\n",
      "   ------------------- -------------------- 97.8/203.0 MB 12.5 MB/s eta 0:00:09\n",
      "   ------------------- ------------------- 100.4/203.0 MB 12.5 MB/s eta 0:00:09\n",
      "   ------------------- ------------------- 103.3/203.0 MB 12.6 MB/s eta 0:00:08\n",
      "   -------------------- ------------------ 106.4/203.0 MB 12.6 MB/s eta 0:00:08\n",
      "   -------------------- ------------------ 109.1/203.0 MB 12.6 MB/s eta 0:00:08\n",
      "   --------------------- ----------------- 111.7/203.0 MB 12.6 MB/s eta 0:00:08\n",
      "   --------------------- ----------------- 114.3/203.0 MB 12.6 MB/s eta 0:00:08\n",
      "   ---------------------- ---------------- 117.2/203.0 MB 12.6 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 120.1/203.0 MB 12.6 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 122.2/203.0 MB 12.6 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 124.5/203.0 MB 12.5 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 126.9/203.0 MB 12.5 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 129.5/203.0 MB 12.5 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 132.1/203.0 MB 12.5 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 134.7/203.0 MB 12.5 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 137.4/203.0 MB 12.5 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 139.7/203.0 MB 12.5 MB/s eta 0:00:06\n",
      "   --------------------------- ----------- 142.6/203.0 MB 12.5 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 146.8/203.0 MB 12.6 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 149.4/203.0 MB 12.6 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 152.3/203.0 MB 12.6 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 154.9/203.0 MB 12.6 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 157.8/203.0 MB 12.7 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 160.4/203.0 MB 12.7 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 162.5/203.0 MB 12.6 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 164.9/203.0 MB 12.6 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 167.5/203.0 MB 12.6 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 170.4/203.0 MB 12.6 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 173.3/203.0 MB 12.6 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 176.2/203.0 MB 12.7 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 178.5/203.0 MB 12.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 180.9/203.0 MB 12.6 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 183.2/203.0 MB 12.6 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 184.0/203.0 MB 12.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 186.1/203.0 MB 12.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 188.2/203.0 MB 12.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 190.6/203.0 MB 12.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 192.9/203.0 MB 12.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 195.6/203.0 MB 12.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.2/203.0 MB 12.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  201.1/203.0 MB 12.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.9/203.0 MB 12.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.9/203.0 MB 12.4 MB/s eta 0:00:01\n",
      "   --------------------------------------- 203.0/203.0 MB 12.1 MB/s eta 0:00:00\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 3.1/6.2 MB 23.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.5/6.2 MB 16.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 14.6 MB/s eta 0:00:00\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "Using cached jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 536.2/536.2 kB 8.8 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, sympy, networkx, MarkupSafe, fsspec, filelock, jinja2, torch, torchvision\n",
      "Successfully installed MarkupSafe-3.0.2 filelock-3.16.1 fsspec-2024.12.0 jinja2-3.1.5 mpmath-1.3.0 networkx-3.4.2 sympy-1.13.1 torch-2.5.1 torchvision-0.20.1\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
